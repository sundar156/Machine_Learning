{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import IntegerType, ShortType\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_train_node = 'train.csv'\n",
    "file_train_feat = 'user_features.csv'\n",
    "file_test_node = 'test.csv'\n",
    "\n",
    "schema_train_node = StructType([\n",
    "    StructField(\"node1_id\", IntegerType()),\n",
    "    StructField(\"node2_id\", IntegerType()),\n",
    "    StructField(\"is_chat\", ShortType()),\n",
    "])\n",
    "\n",
    "schema_train_feat = StructType([\n",
    "    StructField(\"node_id\", IntegerType()),\n",
    "    StructField(\"f1\", ShortType()),\n",
    "    StructField(\"f2\", ShortType()),\n",
    "    StructField(\"f3\", ShortType()),\n",
    "    StructField(\"f4\", ShortType()),\n",
    "    StructField(\"f5\", ShortType()),\n",
    "    StructField(\"f6\", ShortType()),\n",
    "    StructField(\"f7\", ShortType()),\n",
    "    StructField(\"f8\", ShortType()),\n",
    "    StructField(\"f9\", ShortType()),\n",
    "    StructField(\"f10\", ShortType()),\n",
    "    StructField(\"f11\", ShortType()),\n",
    "    StructField(\"f12\", ShortType()),\n",
    "    StructField(\"f13\", ShortType()),\n",
    "])\n",
    "\n",
    "schema_test_node = StructType([\n",
    "    StructField(\"id\", IntegerType()),\n",
    "    StructField(\"node1_id\", IntegerType()),\n",
    "    StructField(\"node2_id\", IntegerType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create sparksession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"hikeathon\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_node = spark.read.csv(file_train_node, header=True, schema=schema_train_node)\n",
    "train_feat = spark.read.csv(file_train_feat, header=True, schema=schema_train_feat)\n",
    "\n",
    "test_node = spark.read.csv(file_test_node, header=True, schema=schema_test_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature is_prev_chat\n",
    "train_node.registerTempTable('original')\n",
    "train_node.registerTempTable('other')\n",
    "prev_is_chat = spark.sql(\"\"\"select original.node1_id, original.node2_id, original.is_chat,\n",
    "                      coalesce(other.is_chat, 0) as prev_is_chat \n",
    "                      from original left join other\n",
    "                      on original.node1_id = other.node2_id\n",
    "                      and original.node2_id = other.node1_id\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev_is_chat.registerTempTable('ip')\n",
    "train_feat.registerTempTable('tf')\n",
    "node_one = spark.sql(\"\"\"select ip.node1_id, ip.node2_id, ip.prev_is_chat, ip.is_chat,\n",
    "                             tf.f1 as f1_n1, tf.f2 as f2_n1, tf.f3 as f3_n1, tf.f4 as f4_n1,\n",
    "                             tf.f5 as f5_n1, tf.f6 as f6_n1, tf.f7 as f7_n1, tf.f8 as f8_n1,\n",
    "                             tf.f9 as f9_n1, tf.f10 as f10_n1, tf.f12 as f12_n1, tf.f13 as f13_n1\n",
    "                             from ip left join tf on tf.node_id = ip.node1_id\"\"\")\n",
    "node_one.registerTempTable('n1_feat')\n",
    "train = spark.sql(\"\"\"select n1_feat.*,\n",
    "                             tf.f1 as f1_n2, tf.f2 as f2_n2, tf.f3 as f3_n2, tf.f4 as f4_n2,\n",
    "                             tf.f5 as f5_n2, tf.f6 as f6_n2, tf.f7 as f7_n2, tf.f8 as f8_n2,\n",
    "                             tf.f9 as f9_n2, tf.f10 as f10_n2, tf.f12 as f12_n2, tf.f13 as f13_n2\n",
    "                             from n1_feat left join tf on tf.node_id = n1_feat.node2_id\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(node1_id=4199003, node2_id=148, prev_is_chat=0, is_chat=0, f1_n1=31, f2_n1=31, f3_n1=31, f4_n1=31, f5_n1=31, f6_n1=31, f7_n1=31, f8_n1=31, f9_n1=31, f10_n1=30, f12_n1=30, f13_n1=7, f1_n2=31, f2_n2=30, f3_n2=0, f4_n2=31, f5_n2=30, f6_n2=0, f7_n2=31, f8_n2=30, f9_n2=0, f10_n2=31, f12_n2=0, f13_n2=15),\n",
       " Row(node1_id=178118, node2_id=148, prev_is_chat=0, is_chat=0, f1_n1=4, f2_n1=0, f3_n1=0, f4_n1=6, f5_n1=0, f6_n1=0, f7_n1=5, f8_n1=0, f9_n1=0, f10_n1=6, f12_n1=0, f13_n1=15, f1_n2=31, f2_n2=30, f3_n2=0, f4_n2=31, f5_n2=30, f6_n2=0, f7_n2=31, f8_n2=30, f9_n2=0, f10_n2=31, f12_n2=0, f13_n2=15),\n",
       " Row(node1_id=7334223, node2_id=148, prev_is_chat=0, is_chat=0, f1_n1=31, f2_n1=1, f3_n1=1, f4_n1=26, f5_n1=2, f6_n1=1, f7_n1=20, f8_n1=2, f9_n1=1, f10_n1=13, f12_n1=1, f13_n1=7, f1_n2=31, f2_n2=30, f3_n2=0, f4_n2=31, f5_n2=30, f6_n2=0, f7_n2=31, f8_n2=30, f9_n2=0, f10_n2=31, f12_n2=0, f13_n2=15),\n",
       " Row(node1_id=5573525, node2_id=148, prev_is_chat=0, is_chat=0, f1_n1=31, f2_n1=6, f3_n1=0, f4_n1=31, f5_n1=6, f6_n1=0, f7_n1=31, f8_n1=6, f9_n1=0, f10_n1=31, f12_n1=0, f13_n1=15, f1_n2=31, f2_n2=30, f3_n2=0, f4_n2=31, f5_n2=30, f6_n2=0, f7_n2=31, f8_n2=30, f9_n2=0, f10_n2=31, f12_n2=0, f13_n2=15),\n",
       " Row(node1_id=4682541, node2_id=148, prev_is_chat=0, is_chat=0, f1_n1=0, f2_n1=0, f3_n1=0, f4_n1=0, f5_n1=0, f6_n1=0, f7_n1=0, f8_n1=0, f9_n1=0, f10_n1=0, f12_n1=0, f13_n1=8, f1_n2=31, f2_n2=30, f3_n2=0, f4_n2=31, f5_n2=30, f6_n2=0, f7_n2=31, f8_n2=30, f9_n2=0, f10_n2=31, f12_n2=0, f13_n2=15)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder_name = 'features_{}'.format(datetime.strftime(datetime.now(pytz.timezone('Asia/Kolkata')), '%Y%m%d_%H%M%S'))\n",
    "train.repartition(1).write.parquet(folder_name, compression='uncompressed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
